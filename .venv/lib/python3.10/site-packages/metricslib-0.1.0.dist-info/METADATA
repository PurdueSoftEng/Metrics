Metadata-Version: 2.1
Name: metricslib
Version: 0.1.0
Classifier: Programming Language :: Rust
Classifier: Programming Language :: Python :: Implementation :: CPython
Classifier: Programming Language :: Python :: Implementation :: PyPy
License-File: LICENSE
Requires-Python: >=3.7
Description-Content-Type: text/markdown; charset=UTF-8; variant=GFM

# Team 12's CLI Tool Implementation for Part 2

## Implementation from Handoff with Team 19
### Implemented from ECE461_Team19_CLI

User should run `./run install`, then either `./run build` -> `./run file_name` to run the program or `./run tests` to run tests.

#### `./run install`

Installs rustup if not found. Then, installs llvm tools (unless on eceprog).

#### `./run build`

Builds the binary

#### `./run tests`

Runs internal tests. Reports test cases passed and line coverage of tests.

#### `./run file_name`

For file, each line should contain one URL. The command reads the URLs, calculates metrics, then prints sorted output to stdout.

#### Supported URL

GitHub URLs and Npm package URLs that are hosted on GitHub are supported.

## New Implemented Metrics

For Part 2 of the project we implemented two new metrics. 

### New Metric #1: Good Pinning Practice

This metric tests the fraction of dependencies that are pinned to at least a specific major+minor vesion of a package. 

### New Metric #2: Code Review

This metric tests the fraction of project code that was introduced through pull requests with a code review.

## Updating the Repository

For part 2 we also updated our Github repository to be both a binary and library. To incorporate a connection with our REST-ful API,
we set up the Github as a library with the addition of a lib.rs file. For use with the Python Flask API we created a submodule in a new repository to access the library.





